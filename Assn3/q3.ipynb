{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mnist import MNIST\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=500)\n",
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = MNIST('./dataset')\n",
    "x_train, y_train = mnist.load_training()\n",
    "x_test, y_test = mnist.load_testing() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.asarray(x_train).astype(np.float32)\n",
    "y_train = np.asarray(y_train).astype(np.int32)\n",
    "x_test = np.asarray(x_test).astype(np.float32)\n",
    "y_test = np.asarray(y_test).astype(np.int32)\n",
    "x_trainmlp = sc.fit_transform(x_train)\n",
    "x_testmlp = sc.transform(x_test)\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28,1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional Neural Network implemented using Tensorflow, keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/requests/__init__.py:83: RequestsDependencyWarning: Old version of cryptography ([1, 2, 3]) may cause slowdown.\n",
      "  warnings.warn(warning, RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 36s 602us/sample - loss: 0.4010 - accuracy: 0.9180 - val_loss: 0.0889 - val_accuracy: 0.9737\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 35s 576us/sample - loss: 0.0694 - accuracy: 0.9789 - val_loss: 0.0528 - val_accuracy: 0.9835\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 33s 558us/sample - loss: 0.0474 - accuracy: 0.9850 - val_loss: 0.0518 - val_accuracy: 0.9843\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 37s 613us/sample - loss: 0.0364 - accuracy: 0.9887 - val_loss: 0.0496 - val_accuracy: 0.9844\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 46s 772us/sample - loss: 0.0295 - accuracy: 0.9911 - val_loss: 0.0423 - val_accuracy: 0.9878\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "model_log = model.fit(x_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=5,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy score for MLP\n",
      " 0.9878\n",
      "\n",
      "Confusion matrix for MLP\n",
      " [[ 971    1    1    0    2    1    2    0    1    1]\n",
      " [   0 1133    0    0    0    0    1    1    0    0]\n",
      " [   3    3 1014    2    1    0    0    4    5    0]\n",
      " [   0    1    2  980    0   12    0    3    9    3]\n",
      " [   0    0    0    0  976    0    0    0    0    6]\n",
      " [   0    0    0    2    1  884    1    1    2    1]\n",
      " [   3    2    0    0    2    1  947    0    3    0]\n",
      " [   0    4    9    0    0    0    0 1010    1    4]\n",
      " [   1    0    1    0    0    0    0    0  970    2]\n",
      " [   1    1    0    0    6    4    0    3    1  993]]\n",
      "\n",
      "Classification report for MLP\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       980\n",
      "           1       0.99      1.00      0.99      1135\n",
      "           2       0.99      0.98      0.98      1032\n",
      "           3       1.00      0.97      0.98      1010\n",
      "           4       0.99      0.99      0.99       982\n",
      "           5       0.98      0.99      0.99       892\n",
      "           6       1.00      0.99      0.99       958\n",
      "           7       0.99      0.98      0.99      1028\n",
      "           8       0.98      1.00      0.99       974\n",
      "           9       0.98      0.98      0.98      1009\n",
      "\n",
      "    accuracy                           0.99     10000\n",
      "   macro avg       0.99      0.99      0.99     10000\n",
      "weighted avg       0.99      0.99      0.99     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(x_test)\n",
    "print(\"\\nAccuracy score for MLP\\n\",accuracy_score(y_test, y_pred))\n",
    "print(\"\\nConfusion matrix for MLP\\n\",confusion_matrix(y_test,y_pred))\n",
    "print(\"\\nClassification report for MLP\\n\",classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 50s 827us/sample - loss: 2.3708 - accuracy: 0.0903 - val_loss: 2.3720 - val_accuracy: 0.0892\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 71s 1ms/sample - loss: 2.3708 - accuracy: 0.0904 - val_loss: 2.3720 - val_accuracy: 0.0892\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 54s 900us/sample - loss: 2.3708 - accuracy: 0.0904 - val_loss: 2.3720 - val_accuracy: 0.0892\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 61s 1ms/sample - loss: 2.3708 - accuracy: 0.0904 - val_loss: 2.3720 - val_accuracy: 0.0892\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 53s 887us/sample - loss: 2.3708 - accuracy: 0.0904 - val_loss: 2.3720 - val_accuracy: 0.0892\n"
     ]
    }
   ],
   "source": [
    "model1 = models.Sequential()\n",
    "model1.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model1.add(layers.MaxPooling2D((2, 2)))\n",
    "model1.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model1.add(layers.Dropout(0.25))\n",
    "model1.add(layers.Flatten())\n",
    "model1.add(layers.Dense(128, activation='relu'))\n",
    "model1.add(layers.Dense(10, activation='softmax'))\n",
    "model1.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "model_log = model1.fit(x_train, y_train,\n",
    "          epochs=5,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy score for MLP\n",
      " 0.0892\n",
      "\n",
      "Confusion matrix for MLP\n",
      " [[   0    0    0    0    0  980    0    0    0    0]\n",
      " [   0    0    0    0    0 1135    0    0    0    0]\n",
      " [   0    0    0    0    0 1032    0    0    0    0]\n",
      " [   0    0    0    0    0 1010    0    0    0    0]\n",
      " [   0    0    0    0    0  982    0    0    0    0]\n",
      " [   0    0    0    0    0  892    0    0    0    0]\n",
      " [   0    0    0    0    0  958    0    0    0    0]\n",
      " [   0    0    0    0    0 1028    0    0    0    0]\n",
      " [   0    0    0    0    0  974    0    0    0    0]\n",
      " [   0    0    0    0    0 1009    0    0    0    0]]\n",
      "\n",
      "Classification report for MLP\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       980\n",
      "           1       0.00      0.00      0.00      1135\n",
      "           2       0.00      0.00      0.00      1032\n",
      "           3       0.00      0.00      0.00      1010\n",
      "           4       0.00      0.00      0.00       982\n",
      "           5       0.09      1.00      0.16       892\n",
      "           6       0.00      0.00      0.00       958\n",
      "           7       0.00      0.00      0.00      1028\n",
      "           8       0.00      0.00      0.00       974\n",
      "           9       0.00      0.00      0.00      1009\n",
      "\n",
      "    accuracy                           0.09     10000\n",
      "   macro avg       0.01      0.10      0.02     10000\n",
      "weighted avg       0.01      0.09      0.01     10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subbu/.local/lib/python3.5/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred = model1.predict_classes(x_test)\n",
    "print(\"\\nAccuracy score for MLP\\n\",accuracy_score(y_test, y_pred))\n",
    "print(\"\\nConfusion matrix for MLP\\n\",confusion_matrix(y_test,y_pred))\n",
    "print(\"\\nClassification report for MLP\\n\",classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best case for CNN is the first case giving an accuracy of close to 0.9. Here from the 28X28 size, multiple convolution layers of 32/64 filters of size 3X3. Later the model is flattened, densed into 64 classes and later divided into the 10 layers as there are 10 distinct outputs. This is later passed through 5 epochs of batch size 128. But in comparison with the 2nd case, the model has dropped a convolution layer, uses dropout to increase more convergence and is densed into 128 layers before 10. Unfortunately, it gives a poor accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP Classifier applied for the same data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(20, 3), learning_rate='constant',\n",
       "              learning_rate_init=0.1, max_fun=15000, max_iter=150, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=None, shuffle=True, solver='sgd', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(20, 3), max_iter=150, alpha=1e-4,\n",
    "                    solver='sgd',learning_rate_init=.1)\n",
    "\n",
    "mlp.fit(x_trainmlp, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = mlp.predict(x_testmlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy score for MLP\n",
      " 0.8779\n",
      "\n",
      "Confusion matrix for MLP\n",
      " [[ 906    2    2    0    0    3   10    5   50    2]\n",
      " [   0 1074   14   22    0    1    1    6   16    1]\n",
      " [   6   67  871   34    0    0    6   25   19    4]\n",
      " [   0   49   11  854    0   19    0   56   15    6]\n",
      " [   5    0    1    0  748    4   14    7    6  197]\n",
      " [   7    7    0   45    1  668    8   24   92   40]\n",
      " [   7    3    2    0    4   10  898    8   25    1]\n",
      " [   0    8    5   14    1    3    0  981    3   13]\n",
      " [   4    9    4   10    4   20    6    7  894   16]\n",
      " [   4    2    1    4   13   15    1   63   21  885]]\n",
      "\n",
      "Classification report for MLP\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94       980\n",
      "           1       0.88      0.95      0.91      1135\n",
      "           2       0.96      0.84      0.90      1032\n",
      "           3       0.87      0.85      0.86      1010\n",
      "           4       0.97      0.76      0.85       982\n",
      "           5       0.90      0.75      0.82       892\n",
      "           6       0.95      0.94      0.94       958\n",
      "           7       0.83      0.95      0.89      1028\n",
      "           8       0.78      0.92      0.85       974\n",
      "           9       0.76      0.88      0.81      1009\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.89      0.88      0.88     10000\n",
      "weighted avg       0.89      0.88      0.88     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nAccuracy score for MLP\\n\",accuracy_score(y_test, y_pred))\n",
    "print(\"\\nConfusion matrix for MLP\\n\",confusion_matrix(y_test,y_pred))\n",
    "print(\"\\nClassification report for MLP\\n\",classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(30, 5), max_iter=300,\n",
    "                    solver='sgd', random_state=100,learning_rate = 'adaptive',\n",
    "                    learning_rate_init=.1)\n",
    "\n",
    "mlp.fit(x_trainmlp, y_train)\n",
    "y_pred = mlp.predict(x_testmlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy score for MLP\n",
      " 0.4265\n",
      "\n",
      "Confusion matrix for MLP\n",
      " [[   0    0    0    1    0    5    0  966    4    4]\n",
      " [   0 1105    1    0    0    1    0    6   22    0]\n",
      " [   0    1    5    5    0   18    0  982   14    7]\n",
      " [   0    0    9  843    0   31    0   85   39    3]\n",
      " [   0    0    0    0    0    0    0  982    0    0]\n",
      " [   0    1    0    7    0  453    0  182  241    8]\n",
      " [   0    2    0    0    0    3    0  950    3    0]\n",
      " [   0    0    1    4    0    8    0 1009    6    0]\n",
      " [   0   11    0   10    0   38    0   62  848    5]\n",
      " [   0    3    0    6    0   17    0  971   10    2]]\n",
      "\n",
      "Classification report for MLP\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       980\n",
      "           1       0.98      0.97      0.98      1135\n",
      "           2       0.31      0.00      0.01      1032\n",
      "           3       0.96      0.83      0.89      1010\n",
      "           4       0.00      0.00      0.00       982\n",
      "           5       0.79      0.51      0.62       892\n",
      "           6       0.00      0.00      0.00       958\n",
      "           7       0.16      0.98      0.28      1028\n",
      "           8       0.71      0.87      0.78       974\n",
      "           9       0.07      0.00      0.00      1009\n",
      "\n",
      "    accuracy                           0.43     10000\n",
      "   macro avg       0.40      0.42      0.36     10000\n",
      "weighted avg       0.40      0.43      0.36     10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subbu/.local/lib/python3.5/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nAccuracy score for MLP\\n\",accuracy_score(y_test, y_pred))\n",
    "print(\"\\nConfusion matrix for MLP\\n\",confusion_matrix(y_test,y_pred))\n",
    "print(\"\\nClassification report for MLP\\n\",classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP Classifier with different max iterations, an adaptive learning rate and different hidden states have been attempted.The best case is the first one, having max iterations being 150, solver being stochastic gradient and the hidden states being (20,3), giving an accuracy of 0.88."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], 28*28)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trainsvm = x_train[0:10000]\n",
    "y_trainsvm = y_train[0:10000]\n",
    "x_testsvm = x_test[0:2000]\n",
    "y_testsvm = y_test[0:2000]\n",
    "\n",
    "x_trainsvm = pca.fit_transform(x_trainsvm)\n",
    "x_testsvm = pca.transform(x_testsvm)\n",
    "x_trainsvm = sc.fit_transform(x_trainsvm)\n",
    "x_testsvm = sc.transform(x_testsvm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "subclf = SVC(kernel='linear', C=0.001)\n",
    "subclf.fit(x_trainsvm, y_trainsvm)\n",
    "y_predsvm = subclf.predict(x_testsvm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy score for SVM\n",
      " 0.8585\n",
      "\n",
      "Confusion matrix for SVM\n",
      " [[168   0   1   1   2   1   2   0   0   0]\n",
      " [  1 228   0   1   1   0   2   0   1   0]\n",
      " [  5   9 174   2   0   1   8   4  14   2]\n",
      " [  1   0   7 173   0  11   1   6   4   4]\n",
      " [  0   2   2   0 195   0   4   1   2  11]\n",
      " [  6   2   0   9   2 144   2   3   9   2]\n",
      " [  3   3   0   0   1  11 158   0   2   0]\n",
      " [  0  10   6   2   5   1   0 165   1  15]\n",
      " [  2   5   6   8   5  12   1   2 148   3]\n",
      " [  1   1   0   8  10   1   0   4   5 164]]\n",
      "\n",
      "Classification report for SVM\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93       175\n",
      "           1       0.88      0.97      0.92       234\n",
      "           2       0.89      0.79      0.84       219\n",
      "           3       0.85      0.84      0.84       207\n",
      "           4       0.88      0.90      0.89       217\n",
      "           5       0.79      0.80      0.80       179\n",
      "           6       0.89      0.89      0.89       178\n",
      "           7       0.89      0.80      0.85       205\n",
      "           8       0.80      0.77      0.78       192\n",
      "           9       0.82      0.85      0.83       194\n",
      "\n",
      "    accuracy                           0.86      2000\n",
      "   macro avg       0.86      0.86      0.86      2000\n",
      "weighted avg       0.86      0.86      0.86      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nAccuracy score for SVM\\n\",accuracy_score(y_testsvm, y_predsvm))\n",
    "print(\"\\nConfusion matrix for SVM\\n\",confusion_matrix(y_testsvm, y_predsvm))\n",
    "print(\"\\nClassification report for SVM\\n\",classification_report(y_testsvm, y_predsvm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "subclf = SVC(kernel='poly')\n",
    "subclf.fit(x_trainsvm, y_trainsvm)\n",
    "y_predsvm = subclf.predict(x_testsvm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy score for SVM\n",
      " 0.199\n",
      "\n",
      "Confusion matrix for SVM\n",
      " [[  4 171   0   0   0   0   0   0   0   0]\n",
      " [  0 233   0   0   0   0   1   0   0   0]\n",
      " [  0 188  30   0   1   0   0   0   0   0]\n",
      " [  0 198   0   8   0   0   0   1   0   0]\n",
      " [  0 207   1   1   7   0   0   0   0   1]\n",
      " [  0 160   1   0   0  18   0   0   0   0]\n",
      " [  0 140   0   0   0   1  37   0   0   0]\n",
      " [  0 168   0   1   0   0   0  34   0   2]\n",
      " [  0 190   1   0   0   0   0   0   1   0]\n",
      " [  0 166   0   0   0   0   0   2   0  26]]\n",
      "\n",
      "Classification report for SVM\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.02      0.04       175\n",
      "           1       0.13      1.00      0.23       234\n",
      "           2       0.91      0.14      0.24       219\n",
      "           3       0.80      0.04      0.07       207\n",
      "           4       0.88      0.03      0.06       217\n",
      "           5       0.95      0.10      0.18       179\n",
      "           6       0.97      0.21      0.34       178\n",
      "           7       0.92      0.17      0.28       205\n",
      "           8       1.00      0.01      0.01       192\n",
      "           9       0.90      0.13      0.23       194\n",
      "\n",
      "    accuracy                           0.20      2000\n",
      "   macro avg       0.84      0.18      0.17      2000\n",
      "weighted avg       0.83      0.20      0.17      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nAccuracy score for SVM\\n\",accuracy_score(y_testsvm, y_predsvm))\n",
    "print(\"\\nConfusion matrix for SVM\\n\",confusion_matrix(y_testsvm, y_predsvm))\n",
    "print(\"\\nClassification report for SVM\\n\",classification_report(y_testsvm, y_predsvm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM with  multiple kernels is tested. The best case is with kernel = linear and c = 0.001. The best SVM accuracy is 0.8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
