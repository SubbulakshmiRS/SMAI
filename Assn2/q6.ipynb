{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subbu/.local/lib/python3.5/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.feature_extraction.stop_words module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_extraction.text. Anything that cannot be imported from sklearn.feature_extraction.text is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np \n",
    "from collections import Counter\n",
    "import glob\n",
    "import os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction import stop_words\n",
    "import itertools\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "from sklearn.metrics.cluster import homogeneity_score\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cluster:\n",
    "    K = 5\n",
    "    m = 0\n",
    "    n = 0\n",
    "    centroids = []\n",
    "    itNum = 100\n",
    "\n",
    "    def stat(self, labels_test, predictions):\n",
    "        print(\"RAND score \", adjusted_rand_score(labels_test, predictions))\n",
    "        print(\"Homogeneity score \", homogeneity_score(labels_test, predictions))\n",
    "  \n",
    "    # calculate the Euclidean distance between two vectors\n",
    "    def euclidean_distance(self, trainData, test_row):\n",
    "        a = trainData - test_row\n",
    "        b =  a**2\n",
    "        distances = np.sum(b, axis = 1)\n",
    "        return distances.reshape(-1,1)\n",
    "\n",
    "    def predict(self, testData):\n",
    "        distances = np.zeros([testData.shape[0],self.K])\n",
    "        for k in range(self.K):\n",
    "            d= self.euclidean_distance(testData, self.centroids[k])\n",
    "            distances[:,k] = d.reshape(testData.shape[0])\n",
    "        predictions = np.argmin(distances, axis = 1)\n",
    "        predictions = predictions+1   \n",
    "        return predictions       \n",
    "\n",
    "    def clustering(self, trainData):\n",
    "        for i in range(self.itNum):\n",
    "            distances = np.zeros([self.m,self.K])\n",
    "            for k in range(self.K):\n",
    "                d= self.euclidean_distance(trainData, self.centroids[k])\n",
    "                distances[:,k] = d.reshape(self.m)\n",
    "            predictions = np.argmin(distances, axis = 1)\n",
    "            predictions = predictions+1\n",
    "            labels = np.unique(predictions)\n",
    "\n",
    "            # print(\"should be 5 check\", labels)\n",
    "            for l in range(len(labels)):\n",
    "                pool = np.where(predictions == labels[l])[0]\n",
    "                if len(pool) is not 0:\n",
    "                    self.centroids[l] = np.mean(trainData[pool], axis = 0)\n",
    "\n",
    "        \n",
    "    def prepData(self, fileList):\n",
    "        labels = []\n",
    "        i = 0\n",
    "        for f in fileList:\n",
    "            i = i+1\n",
    "            a = str(f).split('.')\n",
    "            b = str(a[0]).split('_')\n",
    "            labels.append(int(b[1]))\n",
    "        labels = np.array(labels)\n",
    "#         print(\"labels shape\", labels.shape)\n",
    "        vectorizer = TfidfVectorizer(input='filename', decode_error='ignore', \n",
    "                                    lowercase=True, token_pattern=r'\\b[^\\d\\W]+\\b', \n",
    "                                    stop_words=stop_words.ENGLISH_STOP_WORDS)\n",
    "        x = vectorizer.fit_transform(fileList).toarray()\n",
    "        x = np.array(x)\n",
    "        x = x.astype(np.float)\n",
    "        pca = PCA(n_components=1000)\n",
    "        xPCA = pca.fit_transform(x)\n",
    "        # x_normed = (x - x.min(0)) / x.ptp(0)\n",
    "#         print(\"X shape\", xPCA.shape)\n",
    "#         print(\"no of files is \", i)\n",
    "        return labels, xPCA\n",
    "\n",
    "\n",
    "    def cluster(self, TestFile):\n",
    "        fileList = []\n",
    "        for dirpath,_,filenames in os.walk(TestFile):\n",
    "            for f in filenames:\n",
    "                fileList.append(os.path.abspath(os.path.join(dirpath, f)))\n",
    "#         print(fileList[0])\n",
    "        labels, x = self.prepData(fileList)\n",
    "\n",
    "        x_test = x[0:100]\n",
    "        x_train = x[100:]\n",
    "        labels_test = labels[0:100]\n",
    "        labels_train = labels[100:]\n",
    "        self.m, self.n = x_train.shape\n",
    "        i = np.random.randint(0,self.m-1, size=(1, self.K))\n",
    "        index = list(itertools.chain.from_iterable(i))\n",
    "#         print(\"index = \", index)\n",
    "        self.centroids = x[index]\n",
    "        self.clustering(x_train)\n",
    "        predictions = self.predict(x_test)\n",
    "        self.stat(labels_test, predictions)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/subbu/SMAI/Assn2/Question-6/dataset/55_3.txt\n",
      "labels shape (1725,)\n",
      "X shape (1725, 1000)\n",
      "no of files is  1725\n",
      "index =  [275, 1139, 720, 1127, 1402]\n",
      "RAND score  0.33226801740686024\n",
      "Homogeneity score  0.5087377760331913\n"
     ]
    }
   ],
   "source": [
    "cluster_algo = Cluster()\n",
    "predictions = cluster_algo.cluster('./Question-6/dataset/') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
