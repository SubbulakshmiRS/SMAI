{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import collections\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np \n",
    "from sklearn import tree\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "numCols = list()\n",
    "\n",
    "def mode(num_list):\n",
    "    # print(\"len of num_list\", len(num_list))\n",
    "    # print(\"num_list1\", num_list)\n",
    "    num_list = np.array(list(filter(lambda a: a != 'NA', num_list)))\n",
    "    # print(\"num_list2\", num_list)\n",
    "    modev = collections.Counter(num_list).most_common(1)\n",
    "    mode_val = modev[0][0]\n",
    "    return mode_val\n",
    "\n",
    "def prepData(trainData):\n",
    "    # trainData.sort(key=lambda x:x[-1])\n",
    "    for i in range(len(trainData[0])):\n",
    "        for j in range(len(trainData)):\n",
    "            if trainData[j][i] != 'NA' and str.isdigit(trainData[j][i]) :\n",
    "                numCols.append(i)\n",
    "                break\n",
    "    # print(\"NUMCOLS\")\n",
    "    # print(numCols)\n",
    "    for i in numCols:\n",
    "        num_list = list()\n",
    "        for j in range(len(trainData)):\n",
    "            num_list.append(trainData[j][i])\n",
    "        mode_val = mode(num_list)\n",
    "        # print(\"mode\",mode_val)\n",
    "        for j in range(len(num_list)):\n",
    "            if trainData[j][i] == 'NA':\n",
    "                trainData[j][i] = mode_val\n",
    "    return trainData\n",
    "\n",
    "# Split a dataset based on an attribute and an attribute value\n",
    "def splitDataset(split_index, split_value, dataset):\n",
    "    left, right = dataset, dataset\n",
    "    if split_index in numCols :\n",
    "        a = dataset[:,split_index]\n",
    "        b = a.astype(np.float)\n",
    "        c = b<=float(split_value)\n",
    "        d = c.astype(np.float)\n",
    "        indexes = np.where(d == 1)[0]\n",
    "        left = dataset[np.r_[indexes],:]\n",
    "        indexes = np.where(d == 0)[0]\n",
    "        right = dataset[np.r_[indexes],:]\n",
    "    else :\n",
    "        a = dataset[:,split_index]\n",
    "        c = a==split_value\n",
    "        d = c.astype(np.float)\n",
    "        indexes = np.where(d == 1)[0]\n",
    "        left = dataset[np.r_[indexes],:]\n",
    "        indexes = np.where(d == 0)[0]\n",
    "        right = dataset[np.r_[indexes],:]\n",
    "    return left, right\n",
    "\n",
    "# Calculate the Mean squared error for a splitNode dataset\n",
    "def meanSquaredError(left,right):\n",
    "    mse = 0.0\n",
    "    sizeC = 0\n",
    "    groups = np.array([left, right])\n",
    "    for group in groups:\n",
    "        size = float(len(group))\n",
    "        sizeC += size\n",
    "        # avoid divide by zero\n",
    "        if size == 0:\n",
    "            continue\n",
    "        groupVal = group[:,-1]\n",
    "        groupVal = groupVal.astype(np.float)\n",
    "        a = np.full(len(groupVal),np.average(groupVal))\n",
    "        mse += size*mean_squared_error(groupVal, a)\n",
    "    if sizeC != 0:\n",
    "        mse = mse/sizeC\n",
    "    return mse\n",
    "\n",
    "# Create a terminal node(predict price)\n",
    "def terminalNode(groupVal):\n",
    "    outcomes = groupVal[:,-1].astype(np.float)\n",
    "    return float(np.sum(outcomes) / len(outcomes)) \n",
    "\n",
    "# Find split point of least MSE\n",
    "def findSplit(dataset):\n",
    "    #intializing\n",
    "    split_index = 0\n",
    "    split_value = np.unique(dataset[:,0])[0]\n",
    "    split_left, split_right = splitDataset(0, split_value, dataset)\n",
    "    split_mse = meanSquaredError(split_left, split_right)\n",
    "\n",
    "    for index in range(len(dataset[0])-1):\n",
    "        uniqValue = np.unique(dataset[:,index])\n",
    "        for value in uniqValue:\n",
    "            left, right = splitDataset(index, value, dataset)\n",
    "            mse = meanSquaredError(left, right)\n",
    "            if mse < split_mse:\n",
    "                split_index, split_value, split_mse, split_left, split_right = index, value, mse, left, right\n",
    "    return {'indexAttr':split_index, 'valueAttr':split_value, 'left':split_left, 'right':split_right}\n",
    "\n",
    "# Make node terminal or split further\n",
    "def splitNode(node, max_depth, min_size, depth):\n",
    "    left, right = node['left'], node['right']\n",
    "\n",
    "    # check if already terminal node\n",
    "    if left is None or right is None:\n",
    "        node['left'] = terminalNode(left + right)\n",
    "        node['right'] = node['left']\n",
    "        return\n",
    "    # check for max depth\n",
    "    if depth >= max_depth:\n",
    "        node['left'], node['right'] = terminalNode(left), terminalNode(right)\n",
    "        return\n",
    "\n",
    "    if len(left) <= min_size:\n",
    "        node['left'] = terminalNode(left)\n",
    "    else:\n",
    "        node['left'] = findSplit(left)\n",
    "        splitNode(node['left'], max_depth, min_size, depth+1)\n",
    "\n",
    "    if len(right) <= min_size:\n",
    "        node['right'] = terminalNode(right)\n",
    "    else:\n",
    "        node['right'] = findSplit(right)\n",
    "        splitNode(node['right'], max_depth, min_size, depth+1)\n",
    "\n",
    "# Build a decision tree\n",
    "def buildTree(trainData, max_depth, min_size):\n",
    "    root = findSplit(trainData)\n",
    "    splitNode(root, max_depth, min_size, 1)\n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict with a decision tree\n",
    "def predict(node, row):\n",
    "    if node['indexAttr'] in numCols :\n",
    "        # print(row)\n",
    "        # print(node['indexAttr'])\n",
    "        if float(row[node['indexAttr']]) <= float(node['valueAttr']):\n",
    "            if isinstance(node['left'], float):\n",
    "                return node['left']\n",
    "            else :\n",
    "                return predict(node['left'], row)               \n",
    "        else:\n",
    "            if isinstance(node['right'], float):\n",
    "                return node['right']\n",
    "            else :\n",
    "                return predict(node['right'], row)       \n",
    "    else:\n",
    "        if row[node['indexAttr']] == node['valueAttr']:\n",
    "            if isinstance(node['right'], float):\n",
    "                return node['right']\n",
    "            else :\n",
    "                return predict(node['right'], row)\n",
    "        else:\n",
    "            if isinstance(node['right'], float):\n",
    "                return node['right']\n",
    "            else :\n",
    "                return predict(node['right'], row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(trainFile, max_depth, min_size):\n",
    "    with open(trainFile,'r') as f:\n",
    "        reader  = csv.reader(f)\n",
    "        trainData = np.array(list(reader))\n",
    "        #remove id column\n",
    "        trainData = np.delete(trainData, 0, 1)\n",
    "        trainData = np.delete(trainData,0,0)\n",
    "        trainData = prepData(trainData)\n",
    "        validate = trainData[0:400,:]\n",
    "        trainData = trainData[400:,:]\n",
    "        tags = np.empty(len(validate), dtype = \"float\") \n",
    "        predictions = np.empty(len(validate), dtype = \"float\")\n",
    "        root = buildTree(trainData, max_depth, min_size)\n",
    "        for index in range(len(validate)):\n",
    "            # print(\"index \",index)\n",
    "            test_row = validate[index]\n",
    "            prediction = predict(root, test_row)\n",
    "            tags[index] = float(test_row[-1])\n",
    "            predictions[index] = prediction\n",
    "        return tags, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(tags, predictions):\n",
    "    print(\"Mean Absolute Error\", mean_absolute_error(tags, predictions))\n",
    "    print(\"Mean Squared Error\", mean_squared_error(tags, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build and Validate decision tree with Max depth of branch = 5, Min Size of node = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error 31338.641685301136\n",
      "Mean Squared Error 2243741870.4169755\n"
     ]
    }
   ],
   "source": [
    "tags, predictions = train(\"./Datasets/q3/train.csv\",5,5)\n",
    "evaluate(tags, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Build and Validate decision tree with Max depth of branch = 8, Min Size of node = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error 30434.225399228082\n",
      "Mean Squared Error 2052471604.891035\n"
     ]
    }
   ],
   "source": [
    "tags, predictions = train(\"./Datasets/q3/train.csv\",8,8)\n",
    "evaluate(tags, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Build and Validate decision tree with Max depth of branch = 6, Min Size of node = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error 31182.752416984746\n",
      "Mean Squared Error 2081739092.3071074\n"
     ]
    }
   ],
   "source": [
    "tags, predictions = train(\"./Datasets/q3/train.csv\",6,8)\n",
    "evaluate(tags, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best case for the implemented Decision tree, with the least Mean Absolute Error and Mean Squared Error is at Max depth of branch = 8, Min Size of node = 8 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the Data is normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepData(trainData):\n",
    "    # trainData.sort(key=lambda x:x[-1])\n",
    "    for i in range(len(trainData[0])):\n",
    "        for j in range(len(trainData)):\n",
    "            if trainData[j][i] != 'NA' and str.isdigit(trainData[j][i]) :\n",
    "                numCols.append(i)\n",
    "                break\n",
    "    # print(\"NUMCOLS\")\n",
    "    # print(numCols)\n",
    "    for i in numCols:\n",
    "        num_list = list()\n",
    "        for j in range(len(trainData)):\n",
    "            num_list.append(trainData[j][i])\n",
    "        mode_val = mode(num_list)\n",
    "        # print(\"mode\",mode_val)\n",
    "        for j in range(len(num_list)):\n",
    "            if trainData[j][i] == 'NA':\n",
    "                trainData[j][i] = mode_val\n",
    "\n",
    "        a = trainData[:,i].astype(np.float)\n",
    "        a = a - np.mean(a)\n",
    "        a = a / np.std(a)\n",
    "        trainData[:,i] = a.astype(np.str)\n",
    "    return trainData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build and Validate decision tree with Max depth of branch = 5, Min Size of node = 5 (Data normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error 0.38101765860283593\n",
      "Mean Squared Error 0.3316673818557357\n"
     ]
    }
   ],
   "source": [
    "tags, predictions = train(\"./Datasets/q3/train.csv\",5,5)\n",
    "evaluate(tags, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build and Validate decision tree with Max depth of branch = 8, Min Size of node = 8 (Data normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error 0.37058456613029833\n",
      "Mean Squared Error 0.30336472470351533\n"
     ]
    }
   ],
   "source": [
    "tags, predictions = train(\"./Datasets/q3/train.csv\",8,8)\n",
    "evaluate(tags, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build and Validate decision tree with Max depth of branch = 7, Min Size of node = 8 (Data normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error 0.37995771406034945\n",
      "Mean Squared Error 0.307614299940534\n"
     ]
    }
   ],
   "source": [
    "tags, predictions = train(\"./Datasets/q3/train.csv\",7,8)\n",
    "evaluate(tags, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best case for the implemented Decision tree (with Data normalized), with the least Mean Absolute Error and Mean Squared Error is at Max depth of branch = 8, Min Size of node = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison with the inbuilt Decision tree of sklearn, mean choosing and median choosing for all test rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inbuilt implementation of decision tree using sklearn\n",
    "def inbuiltDecisionTree(trainFile):\n",
    "    with open(trainFile,'r') as f:\n",
    "        reader  = csv.reader(f)\n",
    "        trainData = np.array(list(reader))\n",
    "        #remove id column\n",
    "        trainData = np.delete(trainData, 0, 1)\n",
    "        trainData = np.delete(trainData,0,0)\n",
    "        trainData = prepData(trainData)\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        for col in range(len(trainData[0])):\n",
    "            le.fit(trainData[:,col])\n",
    "            trainData[:,col] = le.transform(trainData[:,col])\n",
    "        validate = trainData[0:400,:]\n",
    "        trainData = trainData[400:,:]\n",
    "        tags = validate[:,-1].astype(np.float)\n",
    "        predictions = np.empty(len(validate), dtype = \"float\")\n",
    "        clf = tree.DecisionTreeRegressor()\n",
    "        l = len(trainData)\n",
    "        clf = clf.fit(trainData[:,0:l-1], trainData[:,-1])\n",
    "        predictions = clf.predict(validate)\n",
    "        return tags, predictions\n",
    "\n",
    "#Mean choosing\n",
    "def mean_classifier(trainFile):\n",
    "    with open(trainFile,'r') as f:\n",
    "        reader  = csv.reader(f)\n",
    "        trainData = np.array(list(reader))\n",
    "        #remove id column\n",
    "        trainData = np.delete(trainData, 0, 1)\n",
    "        trainData = np.delete(trainData,0,0)\n",
    "        trainData = prepData(trainData)\n",
    "        validate = trainData[0:400,:]\n",
    "        trainData = trainData[400:,:]\n",
    "        tags = validate[:,-1].astype(np.float)\n",
    "        predictions = np.full(len(validate), np.mean(trainData[:,-1].astype(np.float)))\n",
    "        return tags, predictions\n",
    "\n",
    "#Median choosing\n",
    "def median_classifier(trainFile):\n",
    "    with open(trainFile,'r') as f:\n",
    "        reader  = csv.reader(f)\n",
    "        trainData = np.array(list(reader))\n",
    "        #remove id column\n",
    "        trainData = np.delete(trainData, 0, 1)\n",
    "        trainData = np.delete(trainData,0,0)\n",
    "        trainData = prepData(trainData)\n",
    "        validate = trainData[0:400,:]\n",
    "        trainData = trainData[400:,:]\n",
    "        tags = validate[:,-1].astype(np.float)\n",
    "        predictions = np.full(len(validate), np.median(trainData[:,-1].astype(np.float)))\n",
    "        return tags, predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inbuilt decision tree with Data Normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error 1.39\n",
      "Mean Squared Error 3.815\n"
     ]
    }
   ],
   "source": [
    "tags, predictions = inbuiltDecisionTree(\"./Datasets/q3/train.csv\")\n",
    "evaluate(tags, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean choosing with Data normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error 0.75672820105992\n",
      "Mean Squared Error 1.024717302166257\n"
     ]
    }
   ],
   "source": [
    "tags, predictions = mean_classifier(\"./Datasets/q3/train.csv\")\n",
    "evaluate(tags, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Median choosing with Data normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error 0.71697263567595\n",
      "Mean Squared Error 1.0564554556253556\n"
     ]
    }
   ],
   "source": [
    "tags, predictions = median_classifier(\"./Datasets/q3/train.csv\")\n",
    "evaluate(tags, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our decision tree is impemented using major libraries such as numpy, collections. The tree's training is done on part of the train.csv's data and its validation is done on remaining data. \n",
    "Our implementation is giving its best performance(least Mean Absolute Error and least Mean Squared Error) for Max depth of branch = 8, Min Size of node = 8. It is comparable with the Inbuilt decision tree from sklearn library. It does better than the baseline cases of mean choosing/ median choosing.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
